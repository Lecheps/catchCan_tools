{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fafad64",
   "metadata": {},
   "source": [
    "# Getting geographic information for Langtjern and Birkenes\n",
    "The purpose of this notebook is to  a database with geographic information for the Norwegian basins that are going to be used as a part of the CatchCan project.\n",
    "The starting point for the analysis are the coordinates for the basin, which will be used to delineate the basin using a high resolution 1x1m digital elevation model (DEM) from kartverket: høydedata.no\n",
    "\n",
    "The coordinates for the outlets are: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9969a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The id is the aquamonitor id but it could be any number as long as they are unique\n",
    "stations = {'Birkenes' : {'lat': 6491473,\n",
    "                         'long': 105229,\n",
    "                         'epsg': 25833,\n",
    "                          'station_id' : 108\n",
    "                         },\n",
    "           'Langtjern' : {'lat': 60.37271, #From NVE data\n",
    "                         'long': 9.72746,\n",
    "                         'epsg': 4326,\n",
    "                         'station_id' : 221\n",
    "                         }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55436db",
   "metadata": {},
   "source": [
    "## Loading required packages and getting credentials to connect to the database\n",
    "This loads the python packages required to process the basins as well as the credentials to different virtual machines where the processing will be performed.\n",
    "The credentials are stored in mobiserver.no and obtaining them will fail if that server is not running.\n",
    "The database and the tools necessary to delineate the basins are store in a virtual machine called dtm10. The database is called geonorway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240fc43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "mobiserver password:  ·······\n",
      "vault password:  ···············\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from fabric import Connection\n",
    "import psycopg2\n",
    "import gmaps\n",
    "import pandas.io.sql as sqlio\n",
    "import getpass\n",
    "from io import StringIO\n",
    "import paramiko\n",
    "import sys\n",
    "from time import sleep\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "sys.path.insert(0, \"/home/jovyan/watexr/PROGNOS/\")\n",
    "from prognos_tools.gce_light import gce_api as gce\n",
    "\n",
    "key = getpass.getpass('mobiserver password: ')\n",
    "cloudKey = getpass.getpass('vault password: ')\n",
    "#Querying necessary tokens\n",
    "def query(query,fetch=True):\n",
    "    with psycopg2.connect(user='jose-luis', host='mobiserver.niva.no', port=5432, database='vault',password=key) as db:\n",
    "        with db.cursor() as cursor :\n",
    "            cursor.execute(query)\n",
    "            if fetch:\n",
    "                result = sqlio.read_sql_query(query, db)\n",
    "                return result\n",
    "            \n",
    "gmapsKey = query('''select niva.getToken('gmaps','{}');'''.format(cloudKey)).iloc[0,0]\n",
    "sshKey = query('''select niva.getToken('geonorway_ssh_key','{}');'''.format(cloudKey)).iloc[0,0]\n",
    "cloudKey = json.loads(query('''select niva.getToken('gce_access','{}');'''.format(cloudKey)).iloc[0,0])\n",
    "gmaps.configure(gmapsKey)\n",
    "not_really_a_file = StringIO(sshKey)\n",
    "private_key = paramiko.RSAKey.from_private_key(not_really_a_file)\n",
    "del key,sshKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ddd4b",
   "metadata": {},
   "source": [
    "## Starting the instance containing the database using the google compute engine api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357718e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RUNNING'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'IP of the instance containing the database 35.228.235.237:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check status of instance\n",
    "properties = {'project'      : 'nivacatchment',\n",
    "             'zone'         : 'europe-north1-a',\n",
    "             'instanceType' : \"n1-standard-4\",\n",
    "             'instanceName' : \"dtm10\",\n",
    "             'username'     : \"jose-luis\",\n",
    "             }\n",
    "\n",
    "cloud = gce(properties, cloudKey)\n",
    "del cloudKey\n",
    "\n",
    "#Getting instance info\n",
    "cloud.CommonCalls['custom'] = '''https://compute.googleapis.com/compute/v1/projects/{project}/zones/{zone}/instances/{instanceName}'''\n",
    "info = cloud.get('custom')\n",
    "display(info['status'])\n",
    "#If instance is stopped, start it\n",
    "if info['status'] != 'RUNNING':\n",
    "    cloud.CommonCalls['custom'] = '''https://compute.googleapis.com/compute/v1/projects/{project}/zones/{zone}/instances/{instanceName}/start'''\n",
    "    info = cloud.post('custom')\n",
    "    display(info['status'])\n",
    "    cloud.CommonCalls['custom'] = '''https://compute.googleapis.com/compute/v1/projects/{project}/zones/{zone}/instances/{instanceName}'''\n",
    "    info = cloud.get('custom')\n",
    "    while info['status'] != 'RUNNING':\n",
    "           sleep(2)\n",
    "           info = cloud.get('custom')\n",
    "          \n",
    "geonorway = info['networkInterfaces'][0]['accessConfigs'][0]['natIP']    \n",
    "    \n",
    "display(\"IP of the instance containing the database {}:\".format(geonorway))\n",
    "\n",
    "#The config below can be used to connect to the instance using fabric's Connection\n",
    "config =  {'host' : geonorway, 'user': 'jose-luis', 'connect_kwargs': {'pkey': private_key } }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7bb1c",
   "metadata": {},
   "source": [
    "## Creating schema to store data\n",
    "\n",
    "All the geographic data will be stored in the geonarway database, which is running in the virtual machine called dtm10.\n",
    "IMPORTANT: if you run the cell below, everything in the schema will be erased if it already exist. Make sure you actual want to erase everything and start from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff21da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'catchcan'\n",
    "\n",
    "#Helper functio to query the geonorway database. Returns a pandas dataframe with the results of the query.\n",
    "def query(query,fetch=True):\n",
    "    with psycopg2.connect(user='jose-luis', host=geonorway, port=5432, database='geonorway') as db:\n",
    "        cursor = db.cursor()\n",
    "        cursor.execute(query)\n",
    "        if fetch:\n",
    "            result = sqlio.read_sql_query(query, db)\n",
    "            return result\n",
    "        \n",
    "query('''drop schema if exists {0} cascade;\n",
    "create schema {0};'''.format(schema),fetch=False)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83efcdd3",
   "metadata": {},
   "source": [
    "## Creating table to store the station coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c40f9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>stationname</th>\n",
       "      <th>stationid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>epsg</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Birkenes</td>\n",
       "      <td>108</td>\n",
       "      <td>6.491473e+06</td>\n",
       "      <td>105229.000000</td>\n",
       "      <td>25833</td>\n",
       "      <td>0101000020E964000000000000D0B0F9400000004054C3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Langtjern</td>\n",
       "      <td>221</td>\n",
       "      <td>6.704554e+06</td>\n",
       "      <td>209434.237831</td>\n",
       "      <td>4326</td>\n",
       "      <td>0101000020E9640000F0BE13E7D19009412438A57C6A93...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sid stationname stationid      latitude      longitude   epsg  \\\n",
       "0    1    Birkenes       108  6.491473e+06  105229.000000  25833   \n",
       "1    2   Langtjern       221  6.704554e+06  209434.237831   4326   \n",
       "\n",
       "                                                geom  \n",
       "0  0101000020E964000000000000D0B0F9400000004054C3...  \n",
       "1  0101000020E9640000F0BE13E7D19009412438A57C6A93...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''drop table if exists {0}.stations;\n",
    "create table {0}.stations (sid int generated always as identity,\n",
    "stationName varchar(100) not null,\n",
    "stationID varchar(50) unique not null,\n",
    "latitude double precision not null,\n",
    "longitude double precision not null,\n",
    "epsg int,\n",
    "unique(sid),\n",
    "primary key (sid)\n",
    ");\n",
    "\n",
    "insert into {0}.stations (stationName,stationId,latitude,longitude,epsg) values {1};\n",
    "\n",
    "create index {0}_stations_station_id_idx on {0}.stations(stationId);\n",
    "alter table {0}.stations add column geom geometry(point,25833);\n",
    "update {0}.stations\n",
    "set geom = st_transform(st_setsrid(st_makepoint(longitude,latitude),epsg),25833);\n",
    "\n",
    "update {0}.stations\n",
    "set longitude = st_x(geom),\n",
    "latitude = st_y(geom);\n",
    "\n",
    "select * from {0}.stations;\n",
    "'''.format(schema,','.join(['''('{0}',{station_id},{lat},{long},{epsg})'''.format(i,**stations[i])  for i in stations.keys()]))\n",
    "\n",
    "a = query(sql)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad2d18ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd80ef16ebc14a3abc0d647dbea3f015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing uploaded stations\n",
    "fig = gmaps.figure(map_type=\"TERRAIN\")\n",
    "\n",
    "b = query('''SELECT a.stationname, st_x(st_transform(a.geom,4326)),\n",
    "    st_y(st_transform(a.geom,4326)), a.stationid\n",
    "    FROM {0}.stations a; \n",
    "    '''.format(schema))\n",
    "\n",
    "\n",
    "outlets = [{\"name\": i[0], \"id\": i[3]} for j,i in b.iterrows()]\n",
    "locations = [(float(i[2]),float(i[1])) for j,i in b.iterrows()]\n",
    "info_box_template = \"\"\"\n",
    "<dl>\n",
    "<font color=\"black\">\n",
    "<dt>Name</dt><dd>{name}</dd>\n",
    "<dt>Id</dt><dd>{id}</sup></dd>\n",
    "</font>\n",
    "</dl>\n",
    "\"\"\"                                                \n",
    "outlet_info = [info_box_template.format(**outlet) for outlet in outlets]                                                 \n",
    "marker_layer = gmaps.marker_layer(locations, info_box_content=outlet_info)\n",
    "fig.add_layer(marker_layer)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d140d9",
   "metadata": {},
   "source": [
    "## Computing the basins using the 10m dem\n",
    "\n",
    "### First finding the point in the flow accumulation raster closest to the given coordinates\n",
    "A common problem with coordinates is that they do fall on an actual \"river\". In order for the basin delineation algorithm to work, the given coordinates should fall inside a cell considered a river in the flow accumulation raster. \n",
    "In order to guarantee this we will nudge, if necessary, the given coordinates so they fall in a cell considered to be a river. The process is not fool proof and the results should be quality controlled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32dfa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>stationname</th>\n",
       "      <th>stationid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Langtjern</td>\n",
       "      <td>221</td>\n",
       "      <td>6.704554e+06</td>\n",
       "      <td>209434.237831</td>\n",
       "      <td>0101000020E9640000F0BE13E7D19009412438A57C6A93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Birkenes</td>\n",
       "      <td>108</td>\n",
       "      <td>6.491473e+06</td>\n",
       "      <td>105229.000000</td>\n",
       "      <td>0101000020E964000000000000D0B0F9400000004054C3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sid stationname stationid      latitude      longitude  \\\n",
       "0    2   Langtjern       221  6.704554e+06  209434.237831   \n",
       "1    1    Birkenes       108  6.491473e+06  105229.000000   \n",
       "\n",
       "                                                geom  \n",
       "0  0101000020E9640000F0BE13E7D19009412438A57C6A93...  \n",
       "1  0101000020E964000000000000D0B0F9400000004054C3...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Please note that in the outlet table we will setup the srid of the outlet to 3035 since\n",
    "#that is the epsg of the rasters we use to compute the basins\n",
    "sql = '''drop table if exists {schema}.outlet cascade;\n",
    "create table {schema}.outlet as select sid, stationname, stationid, latitude, longitude, st_transform(geom,25833) as geom from {schema}.stations as a;\n",
    "update {schema}.outlet\n",
    "set latitude=st_y(geom),\n",
    "longitude=st_x(geom);\n",
    "\n",
    "create index {schema}_outlet_idx on {schema}.outlet using gist(geom);\n",
    "alter table {schema}.outlet add primary key (sid);\n",
    "alter table {schema}.outlet add constraint fk_basin\n",
    "foreign key(sid) \n",
    "references {schema}.stations(sid);\n",
    "\n",
    "'''.format(schema=schema)\n",
    "query(sql,fetch=False)\n",
    "display(query('''select * from {schema}.outlet order by latitude desc;'''.format(schema=schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c29372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving outlet to the closest river, within a 500m radius\n",
    "sql = '''update {schema}.outlet as a \n",
    "set geom = \n",
    "case \n",
    "when st_intersects(st_buffer(a.geom,500),b.geom) then\n",
    "(\n",
    "select st_closestpoint(st_union(b.geom),a.geom) from elv.elvenett25833 as b \n",
    "where st_intersects(st_buffer(a.geom,500),b.geom)\n",
    ")\n",
    "else a.geom\n",
    "end\n",
    "from elv.elvenett25833 as b where st_intersects(st_buffer(a.geom,500),b.geom);\n",
    ";\n",
    "update {schema}.outlet\n",
    "set latitude=st_y(geom),\n",
    "longitude=st_x(geom);\n",
    "\n",
    "'''.format(schema=schema)\n",
    "query(sql,fetch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be08f94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gid</th>\n",
       "      <th>sids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gid sids\n",
       "0   12  [2]\n",
       "1   20  [1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading the flow accumulation raster locally. We will do the computation one basin at a time. We exclude the stations in Svalbard\n",
    "#for which we have no elevation data\n",
    "sql = '''with bla as\n",
    "(select sid,stationid,stationname,st_transform(geom,3045) as geom from {schema}.stations)\n",
    "select distinct a.gid, array_agg(sid) as sids\n",
    "from nedborfelt.vassdragsomr as a, bla as b \n",
    "where st_intersects(a.geom,b.geom)\n",
    "group by a.gid;'''.format(schema = schema)\n",
    "\n",
    "a = query(sql)\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be66236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:13,  6.96s/it]\n"
     ]
    }
   ],
   "source": [
    "#Processing all stations within one basin\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Creating temporary directory to download data and place intermediary files\n",
    "with Connection('localhost') as c:\n",
    "    c.local('rm -rf geodata && mkdir geodata')\n",
    "\n",
    "#A river defined as a pixel with more than 1km2  upstream areas (10k cells)\n",
    "def find_nearest_river(pixel):\n",
    "    #Returns index to numpy array\n",
    "    distances = (nonzero[:,0] - pixel[0]) ** 2 + (nonzero[:,1] - pixel[1]) ** 2\n",
    "    nearest_index = np.argmin(distances)\n",
    "#     display(nearest_index)\n",
    "    return nonzero[nearest_index]\n",
    "\n",
    "def coordsFromPixel(i,j):\n",
    "    #i, j are pixel coordinated in the numpy array\n",
    "    long = xoffset + (j+0.5) * px_w  #adding half a pixel width so the coordinates are centered\n",
    "    lat = yoffset + (i+0.5) * px_h  \n",
    "    return long,lat\n",
    "\n",
    "def pixelFromCoord(long,lat):\n",
    "    #Returns index to numpy array\n",
    "    i = (long - xoffset) / px_w\n",
    "    j = (lat - yoffset) / px_h\n",
    "#     display([sid,long,lat,i,j])\n",
    "    return (int(j),int(i))\n",
    "\n",
    "sql = '''select sid, longitude, latitude from {schema}.outlet where sid in ({idList}); '''\n",
    "\n",
    "updateSql = '''update {schema}.outlet\n",
    "set longitude = {long},\n",
    "latitude = {lat}\n",
    "where sid = {sid};\n",
    "\n",
    "update {schema}.outlet\n",
    "set geom = st_setsrid(st_makepoint(longitude,latitude),25833)\n",
    "where sid={sid};\n",
    "'''\n",
    "\n",
    "for i,j in tqdm(a.iterrows()):\n",
    "    gid = j['gid']\n",
    "    sids = j['sids']\n",
    "#     display(gid,sids)    \n",
    "    coords = query(sql.format(schema=schema,idList=str(sids)[1:-1]))\n",
    "    coords.set_index('sid',inplace=True)\n",
    "#     display(coords)\n",
    "    with Connection(**config) as c:\n",
    "        c.get('/home/jose-luis/flatLake/basin_{}_flow_acc.tif'.format(gid),'./geodata/')\n",
    "        dataset = gdal.Open('geodata/basin_{}_flow_acc.tif'.format(gid),gdal.GA_ReadOnly)\n",
    "        xoffset, px_w, rot1, yoffset, rot2, px_h = dataset.GetGeoTransform()\n",
    "#         display([xoffset, px_w, rot1, yoffset, rot2, px_h])\n",
    "        #IMPORTANT: the index order is inverted when loading into a numpy array. \n",
    "        #This is the reason of the index gymnastics in the following code\n",
    "        river = np.array(dataset.GetRasterBand(1).ReadAsArray())\n",
    "        nonzero = np.argwhere(river > 2000)\n",
    "#         display(len(nonzero))\n",
    "        for sid in sids:\n",
    "            long = coords.loc[sid,'longitude']\n",
    "            lat = coords.loc[sid,'latitude']\n",
    "            currentPixel = pixelFromCoord(long,lat)\n",
    "#             display(\"Current flow_acc: {}\".format(river[currentPixel[1],currentPixel[0]]))\n",
    "            riverPixel = find_nearest_river(currentPixel)\n",
    "#             display(\"Updated flow_acc: {}\".format(river[riverPixel[0],riverPixel[1]]))\n",
    "#             display([long,lat,currentPixel,riverPixel])\n",
    "            new_x,new_y = coordsFromPixel(riverPixel[0],riverPixel[1])\n",
    "#             display([sid,long,lat,new_x,new_y])\n",
    "            query(updateSql.format(schema=schema,sid=sid,long=new_x,lat=new_y),fetch=False)\n",
    "    with Connection('localhost') as c:\n",
    "        c.local('rm geodata/basin_{}_flow_acc.tif'.format(gid))\n",
    "    \n",
    "#             display([long,lat,new_x,new_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69db4427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>stationid</th>\n",
       "      <th>gid</th>\n",
       "      <th>vassomr</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>20</td>\n",
       "      <td>Tovdalsvassdraget/Lillesand kommune</td>\n",
       "      <td>2406.825233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>221</td>\n",
       "      <td>12</td>\n",
       "      <td>Drammensvassdraget/Drammensfjorden vest</td>\n",
       "      <td>17212.146367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sid stationid  gid                                  vassomr          area\n",
       "0    1       108   20      Tovdalsvassdraget/Lillesand kommune   2406.825233\n",
       "1    2       221   12  Drammensvassdraget/Drammensfjorden vest  17212.146367"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, '108']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2, '221']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Finding out the gid number for the flow accumulation raster\n",
    "sql = '''with bla as\n",
    "(select sid,stationid,st_transform(geom,3045) as geom from {schema}.stations)\n",
    "select b.sid,b.stationid,a.gid,a.vassomr,st_area(a.geom)/1e6 as area\n",
    "from nedborfelt.vassdragsomr as a, bla as b \n",
    "where st_intersects(a.geom,b.geom);'''.format(schema=schema)\n",
    "\n",
    "a = query(sql)\n",
    "display(a)\n",
    "\n",
    "query('drop table if exists {schema}.basins;'.format(schema=schema),fetch=False)\n",
    "query('''create table {schema}.basins(sid integer not  null,area double precision, geom geometry(multipolygon,25833),\n",
    "primary key (sid),\n",
    "constraint fk_outlet\n",
    "foreign key(sid) \n",
    "references {schema}.outlet(sid)\n",
    ");\n",
    "'''.format(schema=schema),fetch=False)\n",
    "\n",
    "#Creating folder to store results\n",
    "with Connection(**config) as c:\n",
    "    c.run('rm -rf watershed && mkdir watershed')\n",
    "    \n",
    "\n",
    "script='''#! /bin/bash\n",
    "cd watershed\n",
    "rm -f out.* basin.*\n",
    "\n",
    "pgsql2shp -f out{sid}.shp geonorway \"select sid as id, geom from {schema}.outlet where sid={sid}\"\n",
    "mpiexec -n 4 gagewatershed -p /home/jose-luis/flatLake/basin_{gid}_flow_dir.tif -o out{sid}.shp -gw watershed_{sid}.tif\n",
    "gdal_polygonize.py -8 -f \"ESRI Shapefile\" watershed_{sid}.tif basin{sid}.shp\n",
    "shp2pgsql -d -s 25833 basin{sid}.shp {schema}.temp | psql -d geonorway\n",
    "echo \"insert into {schema}.basins(sid,geom) select dn, st_makevalid(geom) from {schema}.temp;\" | psql -d geonorway\n",
    "'''\n",
    "\n",
    "for i,j in a.iterrows():   \n",
    "# for sid in sids:\n",
    "#     sid=j['station_id']\n",
    "    display([j['sid'],j['stationid']])\n",
    "    with Connection(**config) as c:\n",
    "        with open('script.sh','w') as f:\n",
    "            cond = {'sid': j['sid'], 'gid': j['gid'], 'schema': schema}\n",
    "            f.write(script.format(**cond))\n",
    "        c.put('script.sh')\n",
    "        c.run('chmod +x script.sh')\n",
    "        c.run('./script.sh',hide='both')\n",
    "    \n",
    "\n",
    "query('update {schema}.basins set area=st_area(geom)'.format(schema=schema),fetch=False);\n",
    "query('create index {schema}_basins_idx on {schema}.basins using gist(geom);'.format(schema=schema),fetch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bec2cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa61c511fba4295b2ba245a635979c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = query('''SELECT json_build_object('type', 'FeatureCollection',\n",
    "                                      'features', json_agg(json_build_object(\n",
    "                                                                'type',       'Feature',\n",
    "                                                                'label',      b.stationname,\n",
    "                                                                'geometry',   ST_AsGeoJSON(ST_ForceRHR(St_Transform(a.geom,4326)))::json,\n",
    "                                                                'properties', jsonb_set(row_to_json(a)::jsonb,'{{a.geom}}','0',false)\n",
    "                                                                )\n",
    "                                                            )\n",
    "                                     )\n",
    "             FROM {0}.basins as a join {0}.outlet as b on b.sid=a.sid;'''.format(schema))\n",
    "\n",
    "fig = gmaps.figure(map_type=\"TERRAIN\")\n",
    "fig.add_layer(gmaps.geojson_layer(a.iloc[0,0]))\n",
    "\n",
    "b = query('''SELECT a.stationname, st_x(st_transform(a.geom,4326)),\n",
    "    st_y(st_transform(a.geom,4326)), c.area/1e6 as area, a.sid\n",
    "    FROM {0}.outlet AS a\n",
    "    JOIN {0}.basins as c\n",
    "    on a.sid=c.sid\n",
    "    '''.format(schema))\n",
    "\n",
    "\n",
    "outlets = [{\"name\": i[0], \"area\": i[3], \"id\": i[4]} for j,i in b.iterrows()]\n",
    "locations = [(float(i[2]),float(i[1])) for j,i in b.iterrows()]\n",
    "info_box_template = \"\"\"\n",
    "<dl>\n",
    "<font color=\"black\">\n",
    "<dt>Name</dt><dd>{name}</dd>\n",
    "<dt>Id</dt><dd>{id}</sup></dd>\n",
    "<dt>Area</dt><dd>{area} km<sup>2</sup></dd>\n",
    "</font>\n",
    "</dl>\n",
    "\"\"\"                                                \n",
    "outlet_info = [info_box_template.format(**outlet) for outlet in outlets]                                                 \n",
    "marker_layer = gmaps.marker_layer(locations, info_box_content=outlet_info)\n",
    "fig.add_layer(marker_layer)\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20783362",
   "metadata": {},
   "source": [
    "## Getting 1m elevation data from the 1x1m DEM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d144ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>gruppe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1213-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sid   gruppe\n",
       "0    1    11-10\n",
       "1    2  1213-11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The 1m data cannot be downloaded all at once. It is split in groups. First we find out which groups need to \n",
    "#downloaded\n",
    "intersection =  query( '''select distinct b.sid,a.gruppe from nhm.gruppering as a,\n",
    "{schema}.basins as b\n",
    "where st_intersects(st_buffer(a.geom,1000),b.geom)'''.format(schema=schema))\n",
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d282acbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DTM1 10-10': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/29',\n",
       "  36233),\n",
       " 'DTM1 11-10': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/33',\n",
       "  56086),\n",
       " 'DTM1 12-10': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/38',\n",
       "  10680),\n",
       " 'DTM1 10-11': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/30',\n",
       "  47830),\n",
       " 'DTM1 11-11': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/34',\n",
       "  77848),\n",
       " 'DTM1 1213-11': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/40',\n",
       "  91526),\n",
       " 'DTM1 10-12': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/31',\n",
       "  54112),\n",
       " 'DTM1 11-12': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/35',\n",
       "  70487),\n",
       " 'DTM1 1213-12': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/41',\n",
       "  101642),\n",
       " 'DTM1 10-13': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/32',\n",
       "  18379),\n",
       " 'DTM1 11-13': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/36',\n",
       "  67395),\n",
       " 'DTM1 1213-13': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/42',\n",
       "  92861),\n",
       " 'DTM1 11-14': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/37', 8022),\n",
       " 'DTM1 12-14': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/39',\n",
       "  59627),\n",
       " 'DTM1 13-14': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/45',\n",
       "  36746),\n",
       " 'DTM1 1213-15': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/43',\n",
       "  70663),\n",
       " 'DTM1 1214-16': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/44',\n",
       "  48743),\n",
       " 'DTM1 13-1718': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/46',\n",
       "  11492),\n",
       " 'DTM1 14-17': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/47',\n",
       "  50211),\n",
       " 'DTM1 14-1819': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/48',\n",
       "  34422),\n",
       " 'DTM1 15-1718': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/49',\n",
       "  59206),\n",
       " 'DTM1 16-18': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/51',\n",
       "  59041),\n",
       " 'DTM1 15-19': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/50',\n",
       "  17062),\n",
       " 'DTM1 16-1920': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/52',\n",
       "  60065),\n",
       " 'DTM1 1718-1820': ('https://hoydedata.no/LaserInnsyn/Home/DownloadFile/53',\n",
       "  59549)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The total size of the available dtm data is 1299.928 GB'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Figuring out the link of the group that needs to be dowloaded using bs4\n",
    "baseURL = 'https://hoydedata.no/LaserInnsyn/'\n",
    "\n",
    "def getSoup(url,re_str):\n",
    "    s=requests.Session()\n",
    "    only_a_tags = SoupStrainer(\"a\", href=True)\n",
    "    request=s.get(url)\n",
    "    soup = BeautifulSoup(request.text,'lxml')\n",
    "    links = {i.a.text : (urljoin(baseURL,i.a['href']),int(i.find_all('td')[1].text.replace(u'\\xa0MB', u' ')))  \n",
    "            for i in soup.find_all('tr',{'class':\"dlContent sone33\"})\n",
    "            if i.a and re_str in i.a.text}\n",
    "    return links\n",
    "\n",
    "dtm1_links = getSoup(baseURL,'DTM1 ')\n",
    "display(dtm1_links,'',\n",
    "        'The total size of the available dtm data is {} GB'.format(sum([value[1] for dummy,value in dtm1_links.items()])/1000)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d321c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The groups that need to be downloaded are:\n",
    "\n",
    "download_links = [value for key, value in dtm1_links.items() if any(x in key for x in list(intersection.gruppe))]\n",
    "#Performing download. This takes a while, check that it hasn't been downloaded before.\n",
    "if False: #Change to true if not already downloaded\n",
    "    for i in download_links:\n",
    "        display('''Downloading {} with size {} MB'''.format(i[0],i[1]))\n",
    "        filename = '/home/jovyan/shared/' + i[0].split('/')[-1] + '.zip'\n",
    "        wget.download(i[0],filename)\n",
    "        with zipfile.ZipFile(filename,\"r\") as zip_ref:\n",
    "            zip_ref.extractall(\"/home/jovyan/shared/geodata/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cd51494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tilelist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[/home/jovyan/shared/geodata/33-113-104.tif]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[/home/jovyan/shared/geodata/33-120-118.tif]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tilelist\n",
       "sid                                              \n",
       "1    [/home/jovyan/shared/geodata/33-113-104.tif]\n",
       "2    [/home/jovyan/shared/geodata/33-120-118.tif]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now getting the actual tiles that cover the basins\n",
    "a = query('''select a.sid,array_agg('/home/jovyan/shared/geodata/' || b.name || '.tif') as tilelist from nhm.kartblad as b,\n",
    "{schema}.basins as a\n",
    "where st_intersects(a.geom,st_buffer(b.geom,1000))\n",
    "group by a.sid;'''.format(schema=schema))\n",
    "a.set_index(\"sid\",inplace=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5db4da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Creating output file that is 2840P x 2720L.\n",
      "Processing 1.tif [1/1] : 0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Creating output file that is 4330P x 5740L.\n",
      "Processing 2.tif [1/1] : 0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "#Merging all the tiles and masking them using the buffered 10m basins\n",
    "for i in a.index:\n",
    "    tiles = a.loc[i]['tilelist']\n",
    "    with Connection('localhost') as c:\n",
    "        #If there are too many tiles this command might fail\n",
    "        #The nodata value should eventually be obtained programatically\n",
    "        c.local('''gdal_merge.py -o {} -n -32767 {}'''.format('{}.tif'.format(i),' '.join(tiles)))\n",
    "        c.local('''gdalwarp -s_srs EPSG:25833 -t_srs EPSG:25833 -srcnodata -32767 -dstnodata -32767 -cutline PG:\"dbname=geonorway host={ip} user='jose-luis'\" -csql 'select st_buffer(geom,1000) from {schema}.basins where sid = {sid}' -crop_to_cutline -of GTiff -overwrite {sid}.tif {sid}_cropped.tif'''.format(schema=schema,sid=i,ip=config['host']),replace_env=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fe47b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the 1m elevation dataset\n",
    "\n",
    "#Adding column with buffered basins so we can add an index to the buffer in order to make the queries using it faster\n",
    "sql = '''alter table catchcan.basins add column if not exists buffer geometry(polygon,25833);\n",
    "update catchcan.basins set buffer = st_buffer(geom,1000);\n",
    "create index if not exists catchcan_basins_buffer_idx on catchcan.basins using gist(buffer);'''\n",
    "query(sql,fetch=False)\n",
    "    \n",
    "#Burning in the river into the raster\n",
    "#Query to select only rivers within the buffer basin\n",
    "sql = '''select st_union(st_intersection(a.geom,b.buffer)) as geom from elv.elvenett25833 as a, {schema}.basins as b where st_intersects(b.buffer,a.geom) and b.sid={sid}'''\n",
    "\n",
    "for i in [1,2]:\n",
    "    with Connection('localhost') as c:\n",
    "        c.local('''cp {sid}_cropped.tif {sid}_rivers.tif && gdal_rasterize -b 1 -burn -20 -add -sql '{sql}'  PG:\"dbname=geonorway host={ip} user='jose-luis'\"  {sid}_rivers.tif '''.format(\n",
    "            sql=sql.format(schema=schema,sid=i),\n",
    "            sid=i,\n",
    "            ip=config['host'] )\n",
    "               )\n",
    "\n",
    "#Creating folder to store results and putting the elevation dataset in the vm\n",
    "with Connection(**config) as c:\n",
    "    c.run('rm -rf watershed && mkdir watershed')\n",
    "    for i in [1,2]:\n",
    "        c.put('{sid}_rivers.tif'.format(sid=i),'watershed/{sid}_rivers.tif'.format(sid=i))\n",
    " \n",
    "    \n",
    "#Preprocessing the DEM\n",
    "script='''#! /bin/bash\n",
    "cd watershed\n",
    "rm -f out.* basin.*\n",
    "\n",
    "mpiexec -n 4 pitremove -z {sid}_rivers.tif -fel {sid}_filled.tif \n",
    "mpiexec -n 4 d8flowdir -fel {sid}_filled.tif -p {sid}_flow_dir.tif\n",
    "mpiexec -n 4 aread8 -p {sid}_flow_dir.tif -nc -ad8 {sid}_flow_acc.tif\n",
    "'''\n",
    "\n",
    "for i in [1,2]:   \n",
    "# for sid in sids:\n",
    "#     sid=j['station_id']\n",
    "#     display([j['sid'],j['stationid']])\n",
    "    with Connection(**config) as c:\n",
    "        with open('script.sh','w') as f:\n",
    "            cond = {'sid': i, 'schema': schema, 'gid' : i}\n",
    "            f.write(script.format(**cond))\n",
    "        c.put('script.sh')\n",
    "        c.run('chmod +x script.sh')\n",
    "        c.run('./script.sh',hide='both')\n",
    "    \n",
    "\n",
    "# query('update {schema}.basins set area=st_area(geom)'.format(schema=schema),fetch=False);\n",
    "# query('create index {schema}_basins_idx on {schema}.basins using gist(geom);'.format(schema=schema),fetch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b3e44b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving the outlet to fall on the flow accumulation raster\n",
    "sql = '''drop table if exists {schema}.outlet_1m;\n",
    "create table {schema}.outlet_1m as select * from {schema}.outlet;\n",
    "select * from {schema}.outlet;'''\n",
    "a = query(sql.format(schema=schema))\n",
    "\n",
    "updateSql = '''update {schema}.outlet_1m\n",
    "set longitude = {long},\n",
    "latitude = {lat}\n",
    "where sid = {sid};\n",
    "\n",
    "update {schema}.outlet_1m\n",
    "set geom = st_setsrid(st_makepoint(longitude,latitude),25833)\n",
    "where sid={sid};\n",
    "'''\n",
    "\n",
    "for i,j in a.iterrows():\n",
    "#     display(coords)\n",
    "    with Connection(**config) as c:\n",
    "        c.get('/home/jose-luis/watershed/{}_flow_acc.tif'.format(j['sid']),'./geodata/')\n",
    "        dataset = gdal.Open('geodata/{}_flow_acc.tif'.format(j['sid']),gdal.GA_ReadOnly)\n",
    "        xoffset, px_w, rot1, yoffset, rot2, px_h = dataset.GetGeoTransform()\n",
    "#         display([xoffset, px_w, rot1, yoffset, rot2, px_h])\n",
    "        #IMPORTANT: the index order is inverted when loading into a numpy array. \n",
    "        #This is the reason of the index gymnastics in the following code\n",
    "        river = np.array(dataset.GetRasterBand(1).ReadAsArray())\n",
    "        nonzero = np.argwhere(river > 10000)\n",
    "#         display(len(nonzero))\n",
    "        \n",
    "        long = j['longitude']\n",
    "        lat = j['latitude']\n",
    "        currentPixel = pixelFromCoord(long,lat)\n",
    "#             display(\"Current flow_acc: {}\".format(river[currentPixel[1],currentPixel[0]]))\n",
    "        riverPixel = find_nearest_river(currentPixel)\n",
    "#             display(\"Updated flow_acc: {}\".format(river[riverPixel[0],riverPixel[1]]))\n",
    "#             display([long,lat,currentPixel,riverPixel])\n",
    "        new_x,new_y = coordsFromPixel(riverPixel[0],riverPixel[1])\n",
    "#             display([sid,long,lat,new_x,new_y])\n",
    "        query(updateSql.format(schema=schema,sid=j['sid'],long=new_x,lat=new_y),fetch=False)\n",
    "    with Connection('localhost') as c:\n",
    "        c.local('rm geodata/{}_flow_acc.tif'.format(j['sid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "057857ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the basins from the 1m DEM\n",
    "query('drop table if exists {schema}.basinsdtm1;'.format(schema=schema),fetch=False)\n",
    "query('''create table {schema}.basinsdtm1(sid integer not  null,area double precision, geom geometry(multipolygon,25833),\n",
    "primary key (sid),\n",
    "constraint fk_outlet\n",
    "foreign key(sid) \n",
    "references {schema}.outlet(sid)\n",
    ");\n",
    "'''.format(schema=schema),fetch=False)\n",
    "\n",
    "script='''pgsql2shp -f out{sid}.shp geonorway \"select sid as id, geom from {schema}.outlet_1m where sid={sid}\"\n",
    "mpiexec -n 4 gagewatershed -p /home/jose-luis/watershed/{sid}_flow_dir.tif -o out{sid}.shp -gw watershed_{sid}.tif\n",
    "gdal_polygonize.py -8 -f \"ESRI Shapefile\" watershed_{sid}.tif basin{sid}.shp\n",
    "shp2pgsql -d -s 25833 basin{sid}.shp {schema}.temp | psql -d geonorway\n",
    "echo \"insert into {schema}.basinsdtm1(sid,geom) select dn, st_makevalid(geom) from {schema}.temp;\" | psql -d geonorway\n",
    "'''\n",
    "\n",
    "for i in a['sid'].values:   \n",
    "# for sid in sids:\n",
    "#     sid=j['station_id']\n",
    "#     display([j['sid'],j['stationid']])\n",
    "    with Connection(**config) as c:\n",
    "        with open('script.sh','w') as f:\n",
    "            cond = {'sid': i, 'schema': schema}\n",
    "            f.write(script.format(**cond))\n",
    "        c.put('script.sh')\n",
    "        c.run('chmod +x script.sh')\n",
    "        c.run('./script.sh',hide='both')\n",
    "        \n",
    "query('update {schema}.basinsdtm1 set area=st_area(geom)'.format(schema=schema),fetch=False);\n",
    "query('create index {schema}_basinsdtm1_idx on {schema}.basins using gist(geom);'.format(schema=schema),fetch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a30a653b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b49ba7a9de47fa9c03c6f3d178b853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = query('''SELECT json_build_object('type', 'FeatureCollection',\n",
    "                                      'features', json_agg(json_build_object(\n",
    "                                                                'type',       'Feature',\n",
    "                                                                'label',      b.stationname,\n",
    "                                                                'geometry',   ST_AsGeoJSON(ST_ForceRHR(St_Transform(a.geom,4326)))::json,\n",
    "                                                                'properties', jsonb_set(row_to_json(a)::jsonb,'{{a.geom}}','0',false)\n",
    "                                                                )\n",
    "                                                            )\n",
    "                                     )\n",
    "             FROM {0}.basinsdtm1 as a join {0}.outlet_1m as b on b.sid=a.sid;'''.format(schema))\n",
    "\n",
    "fig = gmaps.figure(map_type=\"TERRAIN\")\n",
    "fig.add_layer(gmaps.geojson_layer(a.iloc[0,0]))\n",
    "\n",
    "b = query('''SELECT a.stationname, st_x(st_transform(a.geom,4326)),\n",
    "    st_y(st_transform(a.geom,4326)), c.area/1e6 as area, a.sid\n",
    "    FROM {0}.outlet_1m AS a\n",
    "    JOIN {0}.basinsdtm1 as c\n",
    "    on a.sid=c.sid\n",
    "    '''.format(schema))\n",
    "\n",
    "\n",
    "outlets = [{\"name\": i[0], \"area\": i[3], \"id\": i[4]} for j,i in b.iterrows()]\n",
    "locations = [(float(i[2]),float(i[1])) for j,i in b.iterrows()]\n",
    "info_box_template = \"\"\"\n",
    "<dl>\n",
    "<font color=\"black\">\n",
    "<dt>Name</dt><dd>{name}</dd>\n",
    "<dt>Id</dt><dd>{id}</sup></dd>\n",
    "<dt>Area</dt><dd>{area} km<sup>2</sup></dd>\n",
    "</font>\n",
    "</dl>\n",
    "\"\"\"                                                \n",
    "outlet_info = [info_box_template.format(**outlet) for outlet in outlets]                                                 \n",
    "marker_layer = gmaps.marker_layer(locations, info_box_content=outlet_info)\n",
    "fig.add_layer(marker_layer)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c90c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
