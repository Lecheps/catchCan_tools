{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "binary-protest",
   "metadata": {},
   "source": [
    "## Getting token for cds climate store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "african-popularity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "mobiserver password:  ·······\n",
      "vault password:  ···············\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas.io.sql as sqlio\n",
    "import getpass\n",
    "import cdsapi\n",
    "from fabric import Connection\n",
    "from joblib import Parallel,delayed\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import uuid\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from io import StringIO\n",
    "import paramiko\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/home/jovyan/watexr/PROGNOS/\")\n",
    "from prognos_tools.gce_light import gce_api as gce\n",
    "\n",
    "key = getpass.getpass('mobiserver password: ')\n",
    "vaultKey = getpass.getpass('vault password: ')\n",
    "#Querying necessary tokens\n",
    "def query(query,fetch=True):\n",
    "    with psycopg2.connect(user='jose-luis', host='mobiserver.niva.no', port=5432, database='vault',password=key) as db:\n",
    "        with db.cursor() as cursor :\n",
    "            cursor.execute(query)\n",
    "            if fetch:\n",
    "                result = sqlio.read_sql_query(query, db)\n",
    "                return result\n",
    "            \n",
    "copernicusKey = query('''select niva.getToken('copernicusKey','{}');'''.format(vaultKey)).iloc[0,0]\n",
    "cloudKey = json.loads(query('''select niva.getToken('gce_access','{}');'''.format(vaultKey)).iloc[0,0])\n",
    "sshKey = query('''select niva.getToken('geonorway_ssh_key','{}');'''.format(vaultKey)).iloc[0,0]\n",
    "not_really_a_file = StringIO(sshKey)\n",
    "geo_key = paramiko.RSAKey.from_private_key(not_really_a_file)\n",
    "\n",
    "del key,vaultKey,sshKey\n",
    "\n",
    "with Connection('localhost') as c:\n",
    "    c.local('rm -f /home/jovyan/.cdsapirc')\n",
    "    c.local('touch /home/jovyan/.cdsapirc') \n",
    "    c.local('''echo \"url: https://cds.climate.copernicus.eu/api/v2\\n\" >>/home/jovyan/.cdsapirc''')\n",
    "    c.local('''echo \"key: {}\" >>/home/jovyan/.cdsapirc'''.format(copernicusKey))\n",
    "    \n",
    "del copernicusKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-leadership",
   "metadata": {},
   "source": [
    "## Creating folder to store downloaded data on remote machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unusual-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RUNNING'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'35.228.213.48'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Properties of the instance containing the database\n",
    "geo_props = {'project'      : 'nivacatchment',\n",
    "             'zone'         : 'europe-north1-a',\n",
    "             'instanceName' : \"dtm10\",\n",
    "             'username'     : \"jose-luis\",\n",
    "             }\n",
    "\n",
    "#Setting up credential for google cloud\n",
    "cloud = gce(geo_props, cloudKey)\n",
    "\n",
    "\n",
    "#Getting instance info\n",
    "cloud.CommonCalls['custom'] = '''https://compute.googleapis.com/compute/v1/projects/{project}/zones/{zone}/instances/{instanceName}'''\n",
    "info = cloud.get('custom')\n",
    "display(info['status'])\n",
    "#If instance is stopped, start it\n",
    "if info['status'] != 'RUNNING':\n",
    "    cloud.CommonCalls['custom'] = '''https://compute.googleapis.com/compute/v1/projects/{project}/zones/{zone}/instances/{instanceName}/start'''\n",
    "    info = cloud.post('custom')\n",
    "    display(info['status'])\n",
    "    cloud.CommonCalls['custom'] = '''https://compute.googleapis.com/compute/v1/projects/{project}/zones/{zone}/instances/{instanceName}'''\n",
    "    info = cloud.get('custom')\n",
    "    while info['status'] != 'RUNNING':\n",
    "           sleep(2)\n",
    "           info = cloud.get('custom')\n",
    "        \n",
    "del cloudKey        \n",
    "   \n",
    "geo_ip = info['networkInterfaces'][0]['accessConfigs'][0]['natIP']    \n",
    "display(geo_ip)\n",
    "geo_config =  {'host' : geo_ip, 'user': 'jose-luis', 'connect_kwargs': {'pkey': geo_key } }\n",
    "\n",
    "\n",
    "#Directory in the remote machine where the data will be placed\n",
    "download_dir = '/home/jose-luis/era5'\n",
    "with Connection(**geo_config) as c:\n",
    "    c.run('rm -rf {0} && mkdir {0}'.format(download_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-archive",
   "metadata": {},
   "source": [
    "## Querying data from the climate datastore\n",
    "\n",
    "With the key obtained above, we can download data from the copernicus climate datastore. \n",
    "The available datasets are listed in https://cds.climate.copernicus.eu/cdsapp#!/search?type=dataset \n",
    "\n",
    "Let's try getting the potential evapotranspiration directly from the era5-land dataset: https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview\n",
    "\n",
    "The ERA-5 dataset covers the whole world. We will only store data from Europe. It will be extracted from the (remote) global data using the fimex tool.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining extent for Europe\n",
    "#The .cfg file is used to pass the extent to the fimex tool\n",
    "cfgName = 'extractEurope.cfg'   \n",
    "\n",
    "cfgTemplate='''[extract]\n",
    "reduceToBoundingBox.south= 33\n",
    "reduceToBoundingBox.north= 82\n",
    "reduceToBoundingBox.west= -14\n",
    "reduceToBoundingBox.east= 35\n",
    "'''\n",
    "\n",
    "with open(cfgName, 'w') as f:\n",
    "    f.write(cfgTemplate)\n",
    "    \n",
    "# Product and components to download.\n",
    "# These are the variables that should be changed to access other datasets\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "components = ['10m_u_component_of_wind', '10m_v_component_of_wind', '2m_dewpoint_temperature',\n",
    "            '2m_temperature', 'clear_sky_direct_solar_radiation_at_surface', 'mean_sea_level_pressure',\n",
    "            'mean_surface_downward_long_wave_radiation_flux_clear_sky', 'mean_surface_downward_short_wave_radiation_flux_clear_sky', 'potential_evaporation',\n",
    "            'total_cloud_cover',\n",
    "             ]\n",
    "product = 'reanalysis-era5-single-levels'\n",
    "\n",
    "hours = ['00:00','01:00','02:00',\n",
    "'03:00','04:00','05:00',\n",
    "'06:00','07:00','08:00',\n",
    "'09:00','10:00','11:00',\n",
    "'12:00','13:00','14:00',\n",
    "'15:00','16:00','17:00',\n",
    "'18:00','19:00','20:00',\n",
    "'21:00','22:00','23:00'\n",
    "]\n",
    "\n",
    "area = [ 83, -15, 33, 36] #[90,-180,-90,180] for the world\n",
    "#-----------------------------------------------------------------------------------------------------    \n",
    "#The dataset needs to be postprocessed before it can be stored. Here we define the additional operations \n",
    "#To be run in the shell\n",
    "def runInShell(operation,inFile):\n",
    "    outFile = str(uuid.uuid4()) + '.nc'\n",
    "    while True :\n",
    "        with Connection('localhost') as c:\n",
    "            if not os.path(outFile): \n",
    "                try :\n",
    "                    c.local(operation.format(inFile=inFile,outFile=outFile),replace_env=False)\n",
    "                except :\n",
    "                    continue\n",
    "    return outFile\n",
    "                \n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------    \n",
    "# Defining the functions to be applied to this particular dataset, by defaul none are\n",
    "data_modifiers = ['''ncks -O --msa -d longitude,180.1,359.9 -d longitude,0.0,180.0 {inFile} {outFile}''',\n",
    "                 '''ncap2 -O -s \"where(longitude>180)longitude=round(longitude.double()*10.0-3600)/10.0\" {inFile} {outFile}''',\n",
    "                 '''fimex-1.5 -c {} --input.file {{}} --output.file {{}}'''.format(cfgName) \n",
    "                 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "foster-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to download the data, using the modifiers listed in the cell above   \n",
    "#By default it DOES NOT overwrite if the output file exist\n",
    "def getFile(inFile,date,outFile = [],data_modifiers=[]):\n",
    "    #Downloading data\n",
    "    file_to_test = inFile\n",
    "    if outFile :\n",
    "        file_to_test = outFile\n",
    "    if not os.path.isfile(file_to_test):\n",
    "        while True:\n",
    "            if not os.path.isfile(inFile):\n",
    "                try: \n",
    "                    d = cdsapi.Client()\n",
    "                    d.retrieve(\n",
    "                        product,\n",
    "                        {\n",
    "                             'product_type':'reanalysis',\n",
    "                             'variable':components,\n",
    "                            'year':  date.strftime(\"%Y\"),\n",
    "                            'month': date.strftime(\"%m\"),\n",
    "                            'day':   date.strftime(\"%d\"),\n",
    "                            'time': hours,\n",
    "                            'area' : area,\n",
    "                            'format':'netcdf'\n",
    "                        },\n",
    "                         inFile\n",
    "                        )\n",
    "                except:\n",
    "                    with Connection('localhost') as c:\n",
    "                        c.local('rm -f {}'.format(inFile))\n",
    "                    continue\n",
    "            #Postprocessing data        \n",
    "            currentFile = inFile\n",
    "            files_to_delete = []  #Temporary files create by the data modifier functions\n",
    "            for i in data_modifiers:\n",
    "                files_to_delete.append(currentFile)\n",
    "                currentFile = runInShell(i,currentFile)\n",
    "                \n",
    "            #Moving resulting file and cleanup\n",
    "            with Connection('localhost') as c:\n",
    "                if os.path.isfile(currentFile):\n",
    "                    try:\n",
    "                        if files_to_delete:\n",
    "                            c.local('rm -f {}'.format(' '.join(files_to_delete)))\n",
    "                        if outFile :\n",
    "                            with Connection(**geo_config) as f:\n",
    "                                f.put(currentFile,outFile)\n",
    "                            c.local('rm {}'.format(currentFile))\n",
    "#                             c.local('mv {} {}'.format(currentFile,outFile))\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "widespread-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting dates to download data\n",
    "\n",
    "start = datetime.datetime.strptime(\"01-01-1979\", \"%d-%m-%Y\")\n",
    "end = datetime.datetime.strptime(\"08-01-1979\", \"%d-%m-%Y\")\n",
    "# end = datetime.datetime.strptime(\"20-03-2021\", \"%d-%m-%Y\")\n",
    "date_generated = [start + datetime.timedelta(days=x) for x in range(0, (end-start).days)]\n",
    "\n",
    "#The data will be downloaded in parallel in split int the following number of workers (rule of thumb: twice as many workers as processors)\n",
    "max_workers = 2\n",
    "num_files = len(date_generated)\n",
    "\n",
    "#Creating directory to download data\n",
    "# download_dir = '/home/jovyan/shared/era5'\n",
    "# with Connection('localhost') as c:\n",
    "#     c.local('rm -rf {}'.format(download_dir))\n",
    "#     c.local('mkdir {}'.format(download_dir))   \n",
    "\n",
    "#Download function: the date is included in the generated filename   \n",
    "def getData(date):    \n",
    "#     print(date.strftime('%d-%m-%Y'))\n",
    "    filename = '{}.nc'.format(date.strftime('%d-%m-%Y'))\n",
    "    out =  '{}/europe_{}.nc'.format(download_dir,date.strftime('%d-%m-%Y'))\n",
    "    getFile(filename,date,outFile=out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recreational-begin",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9f9cbb4ad988>\u001b[0m in \u001b[0;36mgetFile\u001b[0;34m(inFile, date, outFile, data_modifiers)\u001b[0m\n\u001b[1;32m     13\u001b[0m                     d.retrieve(\n\u001b[0;32m---> 14\u001b[0;31m                         \u001b[0mproduct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                         {\n",
      "\u001b[0;31mNameError\u001b[0m: name 'product' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/runners.py\u001b[0m in \u001b[0;36m_finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m                     \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# done waiting!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/runners.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    945\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-957dc67d581e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1990\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgetFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'world.nc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'world.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-9f9cbb4ad988>\u001b[0m in \u001b[0;36mgetFile\u001b[0;34m(inFile, date, outFile, data_modifiers)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'localhost'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -f {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m#Postprocessing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/fabric/connection.py\u001b[0m in \u001b[0;36mlocal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# Superclass run() uses runners.local, so we can literally just call it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# straight.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mopens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/context.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, command, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \"\"\"\n\u001b[1;32m     94\u001b[0m         \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# NOTE: broken out of run() to allow for runner class injection in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/context.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, runner, command, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msudo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, command, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asynchronous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disowned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/runners.py\u001b[0m in \u001b[0;36m_run_body\u001b[0;34m(self, command, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# Wrap up or promise that we will, depending\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asynchronous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/runners.py\u001b[0m in \u001b[0;36m_finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# to stop prematurely\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# TODO: honor other signals sent to our own process and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0;31m# transmit them to the subprocess before handling 'normally'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/runners.py\u001b[0m in \u001b[0;36msend_interrupt\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \"\"\"\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_proc_stdin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"\\x03\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreturncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/runners.py\u001b[0m in \u001b[0;36mwrite_proc_stdin\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# Encode always, then request implementing subclass to perform the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;31m# actual write to subprocess' stdin.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_proc_stdin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/invoke/runners.py\u001b[0m in \u001b[0;36m_write_proc_stdin\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;31m# NOTE: parent_fd from os.fork() is a read/write pipe attached to our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;31m# forked process' stdout/stdin, respectively.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_fd\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_pty\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;31m# Try to write, ignoring broken pipes if encountered (implies child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0;31m# process exited before the process piping stdin to us finished;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "#Testing the download for a single date\n",
    "with Connection('localhost') as c:\n",
    "    c.local('rm -f world.nc')\n",
    "    \n",
    "date = datetime.datetime(1990,5,5)\n",
    "getFile('world.nc',date)\n",
    "\n",
    "data = xr.load_dataset('world.nc')\n",
    "v10 = data['v10'][0,:,:]\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(v10.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unnecessary-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.46it/s]\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/joblib/externals/loky/backend/queues.py\", line 153, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"/opt/conda/lib/python3.8/site-packages/joblib/externals/loky/backend/reduction.py\", line 271, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"/opt/conda/lib/python3.8/site-packages/joblib/externals/loky/backend/reduction.py\", line 264, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"/opt/conda/lib/python3.8/site-packages/joblib/externals/cloudpickle/cloudpickle_fast.py\", line 563, in dump\n    return Pickler.dump(self, obj)\nTypeError: cannot pickle '_cffi_backend.FFI' object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-463fbe1d2e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %%capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Actually downloading the data for all the dates of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "#Actually downloading the data for all the dates of interest\n",
    "Parallel(n_jobs=max_workers)(delayed(getData)(date) for date in tqdm(date_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-focus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "neither-sustainability",
   "metadata": {},
   "source": [
    "## Check all files have been downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Checking if all the files in the list of dates have been downloaded\n",
    "from parse import *\n",
    "\n",
    "#Getting the dates that have been downloaded from the file name\n",
    "with Connection('localhost') as c:\n",
    "    a = c.local('cd {} && ls -1 *.nc'.format(download_dir,hide='stdout'))\n",
    "#     display(a)                \n",
    "a = a.stdout.split('\\n')\n",
    "a = [ parse('europe_{d}-{m}-{Y}.nc',i) for i in a]\n",
    "a = [i.named for i in a  if i is not None]\n",
    "a = [datetime.datetime(int(i['Y']),int(i['m']),int(i['d'])) for i in a]\n",
    "\n",
    "\n",
    "#Checking the difference between the downloaded files and the list of dates:\n",
    "missing_files = list(set(date_generated) - set(a))\n",
    "missing_files.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(missing_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('missing.pickle','wb') as f:\n",
    "    pickle.dump(missing_files,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('missing.pickle','rb') as f:\n",
    "    bla = pickle.load(f)\n",
    "    \n",
    "display(len(bla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "standing-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 11:32:58,274 INFO Connected (version 2.0, client OpenSSH_7.9p1)\n",
      "2021-03-22 11:32:58,382 INFO Authentication (publickey) successful!\n",
      "2021-03-22 11:32:58,447 INFO [chan 0] Opened sftp connection (server version 3)\n"
     ]
    }
   ],
   "source": [
    "with Connection(**geo_config) as c:\n",
    "    c.put('/home/jovyan/.cdsapirc','/home/jose-luis/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lucky-swift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting getEra.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile getEra.py\n",
    "#! /usr/bin/python3\n",
    "#This script should be run in the geodatabase vm. It downloads era5 data\n",
    "import psycopg2\n",
    "import pandas.io.sql as sqlio\n",
    "import getpass\n",
    "import cdsapi\n",
    "from fabric import Connection\n",
    "from joblib import Parallel,delayed\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import uuid\n",
    "import xarray as xr\n",
    "\n",
    "#Defining extent for Europe\n",
    "#The .cfg file is used to pass the extent to the fimex tool\n",
    "cfgName = 'extractEurope.cfg'   \n",
    "\n",
    "cfgTemplate='''[extract]\n",
    "reduceToBoundingBox.south= 33\n",
    "reduceToBoundingBox.north= 82\n",
    "reduceToBoundingBox.west= -14\n",
    "reduceToBoundingBox.east= 35\n",
    "'''\n",
    "\n",
    "with open(cfgName, 'w') as f:\n",
    "    f.write(cfgTemplate)\n",
    "    \n",
    "# Product and components to download.\n",
    "# These are the variables that should be changed to access other datasets\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "components = ['10m_u_component_of_wind', '10m_v_component_of_wind', '2m_dewpoint_temperature',\n",
    "            '2m_temperature', 'clear_sky_direct_solar_radiation_at_surface', 'mean_sea_level_pressure',\n",
    "            'mean_surface_downward_long_wave_radiation_flux_clear_sky', 'mean_surface_downward_short_wave_radiation_flux_clear_sky', 'potential_evaporation',\n",
    "            'total_cloud_cover',\n",
    "             ]\n",
    "product = 'reanalysis-era5-single-levels'\n",
    "\n",
    "hours = ['00:00','01:00','02:00',\n",
    "'03:00','04:00','05:00',\n",
    "'06:00','07:00','08:00',\n",
    "'09:00','10:00','11:00',\n",
    "'12:00','13:00','14:00',\n",
    "'15:00','16:00','17:00',\n",
    "'18:00','19:00','20:00',\n",
    "'21:00','22:00','23:00'\n",
    "]\n",
    "\n",
    "area = [ 83, -15, 33, 36] #[90,-180,-90,180] for the world\n",
    "#-----------------------------------------------------------------------------------------------------    \n",
    "#The dataset needs to be postprocessed before it can be stored. Here we define the additional operations \n",
    "#To be run in the shell\n",
    "def runInShell(operation,inFile):\n",
    "    outFile = str(uuid.uuid4()) + '.nc'\n",
    "    while True :\n",
    "        with Connection('localhost') as c:\n",
    "            if not os.path(outFile): \n",
    "                try :\n",
    "                    c.local(operation.format(inFile=inFile,outFile=outFile),replace_env=False)\n",
    "                except :\n",
    "                    continue\n",
    "    return outFile\n",
    "                \n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------    \n",
    "# Defining the functions to be applied to this particular dataset, by defaul none are\n",
    "data_modifiers = ['''ncks -O --msa -d longitude,180.1,359.9 -d longitude,0.0,180.0 {inFile} {outFile}''',\n",
    "                 '''ncap2 -O -s \"where(longitude>180)longitude=round(longitude.double()*10.0-3600)/10.0\" {inFile} {outFile}''',\n",
    "                 '''fimex-1.5 -c {} --input.file {{}} --output.file {{}}'''.format(cfgName) \n",
    "                 ]\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------    \n",
    "#Function to download the data, using the modifiers listed in the cell above   \n",
    "#By default it DOES NOT overwrite if the output file exist\n",
    "def getFile(inFile,date,outFile = [],data_modifiers=[]):\n",
    "    #Downloading data\n",
    "    file_to_test = inFile\n",
    "    if outFile :\n",
    "        file_to_test = outFile\n",
    "    if not os.path.isfile(file_to_test):\n",
    "        while True:\n",
    "            if not os.path.isfile(inFile):\n",
    "                try: \n",
    "                    d = cdsapi.Client()\n",
    "                    d.retrieve(\n",
    "                        product,\n",
    "                        {\n",
    "                             'product_type':'reanalysis',\n",
    "                             'variable':components,\n",
    "                            'year':  date.strftime(\"%Y\"),\n",
    "                            'month': date.strftime(\"%m\"),\n",
    "                            'day':   date.strftime(\"%d\"),\n",
    "                            'time': hours,\n",
    "                            'area' : area,\n",
    "                            'format':'netcdf'\n",
    "                        },\n",
    "                         inFile\n",
    "                        )\n",
    "                except:\n",
    "                    with Connection('localhost') as c:\n",
    "                        c.local('rm -f {}'.format(inFile))\n",
    "                    continue\n",
    "            #Postprocessing data        \n",
    "            currentFile = inFile\n",
    "            files_to_delete = []  #Temporary files create by the data modifier functions\n",
    "            for i in data_modifiers:\n",
    "                files_to_delete.append(currentFile)\n",
    "                currentFile = runInShell(i,currentFile)\n",
    "                \n",
    "            #Moving resulting file and cleanup\n",
    "            with Connection('localhost') as c:\n",
    "                if os.path.isfile(currentFile):\n",
    "                    try:\n",
    "                        if files_to_delete:\n",
    "                            c.local('rm -f {}'.format(' '.join(files_to_delete)))\n",
    "                        c.local('mv {} {}'.format(currentFile,outFile))\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "            break\n",
    "            \n",
    "#-----------------------------------------------------------------------------------------------------    \n",
    "#Setting dates to download data\n",
    "start = datetime.datetime.strptime(\"01-01-1979\", \"%d-%m-%Y\")\n",
    "end = datetime.datetime.strptime(\"08-01-1979\", \"%d-%m-%Y\")\n",
    "# end = datetime.datetime.strptime(\"20-03-2021\", \"%d-%m-%Y\")\n",
    "date_generated = [start + datetime.timedelta(days=x) for x in range(0, (end-start).days)]\n",
    "\n",
    "#The data will be downloaded in parallel in split int the following number of workers (rule of thumb: twice as many workers as processors)\n",
    "max_workers = 2\n",
    "num_files = len(date_generated)\n",
    "\n",
    "#Creating directory to download data\n",
    "download_dir = '/home/jose-luis/era5'\n",
    "with Connection('localhost') as c:\n",
    "    c.local('rm -rf {}'.format(download_dir))\n",
    "    c.local('mkdir {}'.format(download_dir))   \n",
    "\n",
    "#Download function: the date is included in the generated filename   \n",
    "def getData(date):    \n",
    "#     print(date.strftime('%d-%m-%Y'))\n",
    "    filename = '{}.nc'.format(date.strftime('%d-%m-%Y'))\n",
    "    out =  '{}/europe_{}.nc'.format(download_dir,date.strftime('%d-%m-%Y'))\n",
    "    getFile(filename,date,outFile=out) \n",
    "    \n",
    "#-----------------------------------------------------------------------------------------------------  \n",
    "Parallel(n_jobs=max_workers)(delayed(getData)(date) for date in tqdm(date_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "focused-acrylic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 11:34:46,995 INFO Connected (version 2.0, client OpenSSH_7.9p1)\n",
      "2021-03-22 11:34:47,101 INFO Authentication (publickey) successful!\n",
      "2021-03-22 11:34:47,162 INFO [chan 0] Opened sftp connection (server version 3)\n"
     ]
    }
   ],
   "source": [
    "with Connection(**geo_config) as c:\n",
    "    c.put('getEra.py','/home/jose-luis/')\n",
    "    c.run('chmod +x getEra.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
